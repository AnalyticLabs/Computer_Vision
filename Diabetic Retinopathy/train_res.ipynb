{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "LZnyrN79ISIC",
    "outputId": "66084ca3-2dd8-4b89-9940-4a981f972983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "o32SOZXzISy3",
    "outputId": "bf3a12be-a614-4b03-d7ca-5f82049da6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Copy of Untitled2.ipynb'   Untitled1.ipynb\t       Untitled2_res.ipynb\n",
      " diabetic_retinopathy\t    Untitled2.ipynb\n",
      " train.zip\t\t   'Untitled2_res (1).ipynb'\n"
     ]
    }
   ],
   "source": [
    "!unzip -q \"drive/My Drive/Colab Notebooks/train.zip\"\n",
    "!ls \"drive/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tq-4eUCXI0rv"
   },
   "outputs": [],
   "source": [
    "import shutil, os, glob\n",
    " \n",
    "def moveAllFilesinDir(srcDir, dstDir):\n",
    "    # Check if both the are directories\n",
    "    if os.path.isdir(srcDir) and os.path.isdir(dstDir) :\n",
    "        # Iterate over all the files in source directory\n",
    "        for filePath in glob.glob(srcDir + '/*'):\n",
    "            # Move each file to destination Directory\n",
    "            shutil.move(filePath, dstDir);\n",
    "    else:\n",
    "        print(\"srcDir & dstDir should be Directories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ri6hGQYlI2XX"
   },
   "outputs": [],
   "source": [
    "!mkdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nX88LsTRI4KQ"
   },
   "outputs": [],
   "source": [
    "!mkdir tmp/train\n",
    "!mkdir tmp/train/0\n",
    "!mkdir tmp/train/1\n",
    "!mkdir tmp/train/2\n",
    "!mkdir tmp/train/3\n",
    "!mkdir tmp/train/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CX50xFidOtx"
   },
   "outputs": [],
   "source": [
    "moveAllFilesinDir('0', 'tmp/train/0')\n",
    "moveAllFilesinDir('1', 'tmp/train/1')\n",
    "moveAllFilesinDir('2', 'tmp/train/2')\n",
    "moveAllFilesinDir('3', 'tmp/train/3')\n",
    "moveAllFilesinDir('4', 'tmp/train/4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "1CbEvx32dQ9Y",
    "outputId": "bf51dc52-0f86-4b3e-f8f7-9b60bf0a43dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8810\n",
      "4675\n",
      "5042\n",
      "3323\n",
      "2710\n"
     ]
    }
   ],
   "source": [
    "!ls tmp/train/0 | wc -l\n",
    "!ls tmp/train/1 | wc -l\n",
    "!ls tmp/train/2 | wc -l\n",
    "!ls tmp/train/3 | wc -l\n",
    "!ls tmp/train/4 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zoi25qVBdU-K"
   },
   "outputs": [],
   "source": [
    "!mkdir tmp/val\n",
    "!mkdir tmp/val/0\n",
    "!mkdir tmp/val/1\n",
    "!mkdir tmp/val/2\n",
    "!mkdir tmp/val/3\n",
    "!mkdir tmp/val/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzcW0Vr07osf"
   },
   "outputs": [],
   "source": [
    "!mkdir tmp/test\n",
    "!mkdir tmp/test/0\n",
    "!mkdir tmp/test/1\n",
    "!mkdir tmp/test/2\n",
    "!mkdir tmp/test/3\n",
    "!mkdir tmp/test/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmIbZskz7o6b"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"tmp/train/\"\n",
    "NEW_DIR= \"tmp/val/\"\n",
    "\n",
    "list_dir =  os.listdir(BASE_DIR)\n",
    "\n",
    "import random\n",
    "\n",
    "for tdir in list_dir:\n",
    "    list_images = os.listdir(BASE_DIR+tdir)\n",
    "    to_val = random.sample(list_images, len(list_images)//5)\n",
    "    for images in to_val:\n",
    "        os.rename(BASE_DIR + str(tdir) + \"/\"+ images, NEW_DIR + str(tdir) + \"/\" + images )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngD6Id5Yeyxa"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"tmp/val/\"\n",
    "NEW_DIR= \"tmp/test/\"\n",
    "\n",
    "list_dir =  os.listdir(BASE_DIR)\n",
    "\n",
    "import random\n",
    "\n",
    "for tdir in list_dir:\n",
    "    list_images = os.listdir(BASE_DIR+tdir)\n",
    "    to_val = random.sample(list_images, len(list_images)//2)\n",
    "    for images in to_val:\n",
    "        os.rename(BASE_DIR + str(tdir) + \"/\"+ images, NEW_DIR + str(tdir) + \"/\" + images )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "C6erV2dEe3jB",
    "outputId": "8691a201-9cd3-4ec9-fa6d-07c8025c8327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images\n",
      "7048\n",
      "3740\n",
      "4034\n",
      "2659\n",
      "2168\n",
      "Val Images\n",
      "881\n",
      "468\n",
      "504\n",
      "332\n",
      "271\n",
      "Test Images\n",
      "881\n",
      "467\n",
      "504\n",
      "332\n",
      "271\n"
     ]
    }
   ],
   "source": [
    "print('Train Images')\n",
    "!ls tmp/train/0 | wc -l\n",
    "!ls tmp/train/1 | wc -l\n",
    "!ls tmp/train/2 | wc -l\n",
    "!ls tmp/train/3 | wc -l\n",
    "!ls tmp/train/4 | wc -l\n",
    "\n",
    "print('Val Images')\n",
    "!ls tmp/val/0 | wc -l\n",
    "!ls tmp/val/1 | wc -l\n",
    "!ls tmp/val/2 | wc -l\n",
    "!ls tmp/val/3 | wc -l\n",
    "!ls tmp/val/4 | wc -l\n",
    "\n",
    "print('Test Images')\n",
    "!ls tmp/test/0 | wc -l\n",
    "!ls tmp/test/1 | wc -l\n",
    "!ls tmp/test/2 | wc -l\n",
    "!ls tmp/test/3 | wc -l\n",
    "!ls tmp/test/4 | wc -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UyNeDWFBgAAI"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# try:\n",
    "#   # %tensorflow_version only exists in Colab.\n",
    "#   !pip install --upgrade tf-nightly\n",
    "# except Exception:\n",
    "#   pass\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "gIYvr4YNpOcf",
    "outputId": "afb833fa-2867-4cb2-8f78-6c6805b7e30f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-gpu==2 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow-gpu==2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KOVKmryqgFa4",
    "outputId": "ef746e35-c96f-4ccb-d204-59b9c8ce7311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "IyYN9K8qfEEm",
    "outputId": "06687f3a-e26b-4337-d2e2-8d27280d2159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'tmp/train/1/22916_right.jpeg'\n",
      "b'tmp/train/2/41514_right.jpeg'\n",
      "b'tmp/train/1/301_right.jpeg'\n",
      "b'tmp/train/1/230402_right.jpeg'\n",
      "b'tmp/train/3/113716_left.jpeg'\n",
      "b'tmp/val/0/10154_left.jpeg'\n",
      "b'tmp/val/1/40757_left.jpeg'\n",
      "b'tmp/val/1/234567_left.jpeg'\n",
      "b'tmp/val/0/4569_left.jpeg'\n",
      "b'tmp/val/0/34138_right.jpeg'\n"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str('tmp/train/*/*'))\n",
    "list_ds_val = tf.data.Dataset.list_files(str('tmp/val/*/*'))\n",
    "list_ds_test = tf.data.Dataset.list_files(str('tmp/test/*/*'))\n",
    "\n",
    "for f in list_ds.take(5):\n",
    "  print(f.numpy())\n",
    "for f in list_ds_val.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNOUI3fIji6b"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path('tmp/train')\n",
    "data_dir_val = pathlib.Path('tmp/val') \n",
    "data_dir_test = pathlib.Path('tmp/test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "grDoMLoNjvBQ",
    "outputId": "439ea811-8b62-4f1c-9db5-7adc0c5a345d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19649\n",
      "['4' '2' '0' '3' '1']\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpeg')))\n",
    "print(image_count)\n",
    "\n",
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "print(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okdJXyU-grQc"
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, '/')\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == CLASS_NAMES\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9a-Jb64qf7Mh"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=32)\n",
    "labeled_ds_val = list_ds_val.map(process_path, num_parallel_calls=32)\n",
    "labeled_ds_test = list_ds_test.map(process_path, num_parallel_calls=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "C4fbGQbShQIr",
    "outputId": "f5ff8d34-873a-4323-ce16-44beeb76dafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (256, 256, 3)\n",
      "Label:  [False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "for image, label in labeled_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCRqW2i7kuzo"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 256 # All images will be resized to 256*256\n",
    "\n",
    "def format_example(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image/127.5) - 1\n",
    "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtC4L-wSlG4-"
   },
   "outputs": [],
   "source": [
    "raw_train = labeled_ds\n",
    "raw_validation = labeled_ds_val\n",
    "raw_test = labeled_ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eeuSXqelCQ5"
   },
   "outputs": [],
   "source": [
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFu2RcAxlvRF"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "SHUFFLE_BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ur7j35ullyrb"
   },
   "outputs": [],
   "source": [
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RR7YNuWvl1zf",
    "outputId": "208ec96e-7d8e-4e9f-ff8f-357a056fd3f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 256, 256, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "   pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Spzqehel3-R"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "# Create the base model from the pre-trained model \n",
    "base_model = tf.compat.v2.keras.applications.resnet.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c-o4E4Rkl_lG",
    "outputId": "5e23db03-122c-4b13-d1a6-bf19fe7f2acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 8, 2048)\n"
     ]
    }
   ],
   "source": [
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_mC-1fbsZH4"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bCpPBPPS7v_e",
    "outputId": "b775676c-dbfe-4508-a880-e2584cf01965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RKAo7lB87xxr",
    "outputId": "0a177ec6-80bb-4ab5-89ac-f27fc2e8b306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2048)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalMaxPooling2D(data_format=None)\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NA9-KNdv701y",
    "outputId": "afba89e6-9fbf-433f-e395-7bdd131b0fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SxNbYKaK74Qn"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "aWE3W3jD8W_b",
    "outputId": "467d6014-0b44-4cc6-bd8d-4fd1ac4bd4d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msrNqY9l833V"
   },
   "outputs": [],
   "source": [
    "SPLIT_WEIGHTS = (8, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bPRt2dz8g32"
   },
   "outputs": [],
   "source": [
    "num_train = 19649\n",
    "num_val= 2456\n",
    "num_test=2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8cBAOOi8nHZ"
   },
   "outputs": [],
   "source": [
    "initial_epochs = 3\n",
    "steps_per_epoch = round(num_train)//BATCH_SIZE\n",
    "validation_steps = 20\n",
    "\n",
    "#loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)\n",
    "# print(\"initial loss: {:.2f}\".format(loss0))\n",
    "# print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "nzx5jFoX-VQf",
    "outputId": "8bd6742e-638c-44f7-c3f9-dc509abc5a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2457/2457 [==============================] - 320s 130ms/step - loss: 1.1921e-07 - accuracy: 0.6099 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "2457/2457 [==============================] - 315s 128ms/step - loss: 1.1921e-07 - accuracy: 0.6110 - val_loss: 1.1921e-07 - val_accuracy: 0.2000\n",
      "Epoch 3/3\n",
      "2457/2457 [==============================] - 314s 128ms/step - loss: 1.1921e-07 - accuracy: 0.6124 - val_loss: 1.1921e-07 - val_accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_batches,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "id": "0dnpmdTM-Ykh",
    "outputId": "e86a1dff-d2fa-4dc7-9937-97e0db9fd25d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Accuracy')"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHiCAYAAADxm1UyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwJ0dOG8sggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "8E8lqy7s-bgW",
    "outputId": "817bbc4c-e9dd-49ea-dd2b-bd9d55052b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 6s 113ms/step - loss: 1.1921e-07 - accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1920930376163597e-07, 0.1999999]"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batches, steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crIH-8pvwet5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled2_res.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
